# LiteLLM Compatible Providers
# This file defines the supported LLM providers and their configurations

providers:
  # OpenAI
  openai:
    name: "OpenAI"
    models:
      - name: "gpt-3.5-turbo"
        description: "GPT-3.5 Turbo model for general purpose tasks"
        context_window: 16385
        pricing:
          input: 0.0015
          output: 0.002
      - name: "gpt-4"
        description: "GPT-4 model with advanced reasoning capabilities"
        context_window: 8192
        pricing:
          input: 0.03
          output: 0.06
      - name: "gpt-4-turbo"
        description: "GPT-4 Turbo with improved performance and larger context window"
        context_window: 128000
        pricing:
          input: 0.01
          output: 0.03

  # Anthropic
  anthropic:
    name: "Anthropic"
    models:
      - name: "claude-2"
        description: "Claude 2 model for general purpose tasks"
        context_window: 100000
        pricing:
          input: 0.01
          output: 0.03
      - name: "claude-instant-1"
        description: "Faster, more cost-effective Claude model"
        context_window: 100000
        pricing:
          input: 0.0015
          output: 0.0075

  # Google
  google:
    name: "Google"
    models:
      - name: "gemini-pro"
        description: "Google's Gemini Pro model"
        context_window: 32768
        pricing:
          input: 0.00025
          output: 0.0005

  # Azure OpenAI
  azure:
    name: "Azure OpenAI"
    models:
      - name: "gpt-35-turbo"
        description: "Azure hosted GPT-3.5 Turbo"
        context_window: 16385
        pricing:
          input: 0.0015
          output: 0.002
      - name: "gpt-4"
        description: "Azure hosted GPT-4"
        context_window: 8192
        pricing:
          input: 0.03
          output: 0.06

  # Cohere
  cohere:
    name: "Cohere"
    models:
      - name: "command"
        description: "Cohere Command model for general purpose tasks"
        context_window: 4096
        pricing:
          input: 0.0015
          output: 0.0020
      - name: "command-light"
        description: "Lighter version of Cohere Command"
        context_window: 4096
        pricing:
          input: 0.0003
          output: 0.0006

  # Mistral AI
  mistral:
    name: "Mistral AI"
    models:
      - name: "mistral-7b-instruct"
        description: "Mistral 7B instruction-tuned model"
        context_window: 8192
        pricing:
          input: 0.0002
          output: 0.0002
      - name: "mixtral-8x7b-instruct"
        description: "Mixtral 8x7B instruction-tuned model"
        context_window: 32768
        pricing:
          input: 0.0006
          output: 0.0006

  # Ollama (local deployment)
  ollama:
    name: "Ollama"
    models:
      - name: "llama2"
        description: "Locally hosted Llama 2 model"
        context_window: 4096
        pricing:
          input: 0.0
          output: 0.0
      - name: "mistral"
        description: "Locally hosted Mistral model"
        context_window: 8192
        pricing:
          input: 0.0
          output: 0.0

  # Replicate
  replicate:
    name: "Replicate"
    models:
      - name: "llama-2-70b-chat"
        description: "Llama 2 70B chat model hosted on Replicate"
        context_window: 4096
        pricing:
          input: 0.0008
          output: 0.0008
