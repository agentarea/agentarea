#!/usr/bin/env python3
"""DEFINITIVE PROOF: Monkey patching intercepts every tool and LLM call.

This test creates a clear before/after comparison to prove that:
1. Original methods are replaced
2. Intercepted methods are actually called
3. Original methods are NOT called when interception is enabled
"""

import asyncio
import logging
import sys
from typing import Dict, Any
from unittest.mock import AsyncMock, MagicMock, patch

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Global counters to track method calls
ORIGINAL_TOOL_CALLS = 0
ORIGINAL_LLM_CALLS = 0
INTERCEPTED_TOOL_CALLS = 0
INTERCEPTED_LLM_CALLS = 0


async def test_monkey_patch_proof():
    """Definitive proof that monkey patching works."""
    logger.info("üéØ DEFINITIVE MONKEY PATCH PROOF")
    logger.info("=" * 60)
    
    global ORIGINAL_TOOL_CALLS, ORIGINAL_LLM_CALLS, INTERCEPTED_TOOL_CALLS, INTERCEPTED_LLM_CALLS
    
    try:
        # Step 1: Import classes and store original methods
        logger.info("üì¶ Step 1: Importing ADK classes...")
        
        from agentarea_execution.ag.adk.tools.base_tool import BaseTool
        from agentarea_execution.ag.adk.models.base_llm import BaseLlm
        from agentarea_execution.ag.adk.tools.tool_context import ToolContext
        from agentarea_execution.ag.adk.models.llm_request import LlmRequest
        from agentarea_execution.ag.adk.models.llm_response import LlmResponse
        from google.genai import types
        
        # Store references to original methods
        original_tool_run_async = BaseTool.run_async
        original_llm_generate = BaseLlm.generate_content_async
        
        logger.info(f"   Original tool method: {original_tool_run_async}")
        logger.info(f"   Original LLM method: {original_llm_generate}")
        
        # Step 2: Create test classes that track calls to original methods
        logger.info("\nüß™ Step 2: Creating test classes...")
        
        class TestTool(BaseTool):
            def __init__(self):
                super().__init__(name="test_tool", description="Test tool")
                # Store reference to track original calls
                self._original_run_async = original_tool_run_async
            
            async def run_async(self, *, args, tool_context):
                """Implementation that tracks calls."""
                global ORIGINAL_TOOL_CALLS
                ORIGINAL_TOOL_CALLS += 1
                logger.info(f"   üîß ORIGINAL tool method called! Count: {ORIGINAL_TOOL_CALLS}")
                return {"original_tool": True, "args": args}
        
        class TestLlm(BaseLlm):
            def __init__(self):
                super().__init__(model="test-model")
                # Store reference to track original calls
                self._original_generate_content_async = original_llm_generate
            
            async def generate_content_async(self, llm_request, stream=False):
                """Implementation of abstract method that tracks calls."""
                global ORIGINAL_LLM_CALLS
                ORIGINAL_LLM_CALLS += 1
                logger.info(f"   ü§ñ ORIGINAL LLM method called! Count: {ORIGINAL_LLM_CALLS}")
                
                # Return a simple response
                content = types.Content(
                    role="model",
                    parts=[types.Part(text="Original LLM response")]
                )
                
                response = LlmResponse(
                    content=content,
                    partial=False,
                    turn_complete=True
                )
                yield response
        

        
        # Step 3: Test BEFORE interception
        logger.info("\nüîç Step 3: Testing BEFORE interception...")
        
        tool = TestTool()
        llm = TestLlm()
        tool_context = MagicMock(spec=ToolContext)
        llm_request = LlmRequest(
            contents=[types.Content(role="user", parts=[types.Part(text="Test")])]
        )
        
        # Reset counters
        ORIGINAL_TOOL_CALLS = 0
        ORIGINAL_LLM_CALLS = 0
        
        # Call methods - should use original implementations
        tool_result = await tool.run_async(args={"test": "before"}, tool_context=tool_context)
        logger.info(f"   Tool result: {tool_result}")
        
        llm_responses = []
        async for response in llm.generate_content_async(llm_request):
            llm_responses.append(response)
        logger.info(f"   LLM responses: {len(llm_responses)}")
        
        before_tool_calls = ORIGINAL_TOOL_CALLS
        before_llm_calls = ORIGINAL_LLM_CALLS
        
        logger.info(f"   ‚úÖ Before interception - Tool calls: {before_tool_calls}, LLM calls: {before_llm_calls}")
        
        # Step 4: Enable interception
        logger.info("\nüîß Step 4: Enabling interception...")
        
        from agentarea_execution.adk_temporal.interceptors import enable_temporal_backbone
        
        # Enable interception
        enable_temporal_backbone()
        
        # Verify methods were replaced
        new_tool_method = BaseTool.run_async
        new_llm_method = BaseLlm.generate_content_async
        
        tool_patched = new_tool_method != original_tool_run_async
        llm_patched = new_llm_method != original_llm_generate
        
        logger.info(f"   New tool method: {new_tool_method}")
        logger.info(f"   New LLM method: {new_llm_method}")
        logger.info(f"   ‚úÖ Tool method patched: {tool_patched}")
        logger.info(f"   ‚úÖ LLM method patched: {llm_patched}")
        
        if not (tool_patched and llm_patched):
            logger.error("‚ùå Methods were not patched!")
            return False
        
        # Step 5: Test AFTER interception (without workflow context)
        logger.info("\nüîç Step 5: Testing AFTER interception (fallback behavior)...")
        
        # Reset counters
        ORIGINAL_TOOL_CALLS = 0
        ORIGINAL_LLM_CALLS = 0
        INTERCEPTED_TOOL_CALLS = 0
        INTERCEPTED_LLM_CALLS = 0
        
        # Call methods - should be intercepted but fall back to original
        tool_result_after = await tool.run_async(args={"test": "after"}, tool_context=tool_context)
        logger.info(f"   Tool result: {tool_result_after}")
        
        llm_responses_after = []
        async for response in llm.generate_content_async(llm_request):
            llm_responses_after.append(response)
        logger.info(f"   LLM responses: {len(llm_responses_after)}")
        
        after_tool_calls = ORIGINAL_TOOL_CALLS
        after_llm_calls = ORIGINAL_LLM_CALLS
        
        logger.info(f"   ‚úÖ After interception (fallback) - Tool calls: {after_tool_calls}, LLM calls: {after_llm_calls}")
        
        # Step 6: Test WITH workflow context (should be intercepted)
        logger.info("\nüé≠ Step 6: Testing WITH workflow context (should intercept)...")
        
        # Mock workflow context - need to patch the workflow module directly
        mock_workflow_info = MagicMock()
        mock_workflow_info.workflow_id = "test-workflow-123"
        
        def mock_activity_execution(activity_name, args, **kwargs):
            """Mock activity execution that tracks intercepted calls."""
            global INTERCEPTED_TOOL_CALLS, INTERCEPTED_LLM_CALLS
            
            if "tool" in activity_name:
                INTERCEPTED_TOOL_CALLS += 1
                logger.info(f"   üéØ INTERCEPTED tool call! Count: {INTERCEPTED_TOOL_CALLS}")
                return {"intercepted_tool": True, "activity": activity_name}
            else:
                INTERCEPTED_LLM_CALLS += 1
                logger.info(f"   üéØ INTERCEPTED LLM call! Count: {INTERCEPTED_LLM_CALLS}")
                return {
                    "content": "Intercepted LLM response",
                    "role": "assistant",
                    "usage": {"total_tokens": 25},
                    "cost": 0.001
                }
        
        # Reset counters
        ORIGINAL_TOOL_CALLS = 0
        ORIGINAL_LLM_CALLS = 0
        INTERCEPTED_TOOL_CALLS = 0
        INTERCEPTED_LLM_CALLS = 0
        
        # Patch workflow module in both interceptor files
        with patch('agentarea_execution.adk_temporal.interceptors.tool_call_interceptor.workflow.info', return_value=mock_workflow_info), \
             patch('agentarea_execution.adk_temporal.interceptors.tool_call_interceptor.workflow.execute_activity', side_effect=mock_activity_execution), \
             patch('agentarea_execution.adk_temporal.interceptors.llm_call_interceptor.workflow.info', return_value=mock_workflow_info), \
             patch('agentarea_execution.adk_temporal.interceptors.llm_call_interceptor.workflow.execute_activity', side_effect=mock_activity_execution):
            
            # Call methods - should be intercepted and NOT call original methods
            tool_result_intercepted = await tool.run_async(args={"test": "intercepted"}, tool_context=tool_context)
            logger.info(f"   Tool result: {tool_result_intercepted}")
            
            llm_responses_intercepted = []
            async for response in llm.generate_content_async(llm_request):
                llm_responses_intercepted.append(response)
            logger.info(f"   LLM responses: {len(llm_responses_intercepted)}")
        
        intercepted_tool_calls = INTERCEPTED_TOOL_CALLS
        intercepted_llm_calls = INTERCEPTED_LLM_CALLS
        original_tool_calls_during_interception = ORIGINAL_TOOL_CALLS
        original_llm_calls_during_interception = ORIGINAL_LLM_CALLS
        
        logger.info(f"   ‚úÖ Intercepted calls - Tool: {intercepted_tool_calls}, LLM: {intercepted_llm_calls}")
        logger.info(f"   ‚úÖ Original calls during interception - Tool: {original_tool_calls_during_interception}, LLM: {original_llm_calls_during_interception}")
        
        # Step 7: Analyze results
        logger.info("\nüìä Step 7: PROOF ANALYSIS")
        logger.info("=" * 60)
        
        # Proof criteria
        methods_patched = tool_patched and llm_patched
        interception_working = intercepted_tool_calls > 0 and intercepted_llm_calls > 0
        original_bypassed = original_tool_calls_during_interception == 0 and original_llm_calls_during_interception == 0
        
        logger.info(f"‚úÖ Methods successfully patched: {methods_patched}")
        logger.info(f"‚úÖ Interception working in workflow: {interception_working}")
        logger.info(f"‚úÖ Original methods bypassed: {original_bypassed}")
        
        # Final verdict
        proof_complete = methods_patched and interception_working and original_bypassed
        
        if proof_complete:
            logger.info("\nüéâ PROOF COMPLETE!")
            logger.info("‚úÖ MONKEY PATCHING VERIFIED:")
            logger.info("   ‚Ä¢ BaseTool.run_async successfully replaced")
            logger.info("   ‚Ä¢ BaseLlm.generate_content_async successfully replaced")
            logger.info("   ‚Ä¢ Intercepted methods called instead of originals")
            logger.info("   ‚Ä¢ Original methods completely bypassed in workflow context")
            
            logger.info("\nüîí GUARANTEE PROVEN:")
            logger.info("   ‚Ä¢ Every tool call ‚Üí Intercepted method ‚Üí Temporal activity")
            logger.info("   ‚Ä¢ Every LLM call ‚Üí Intercepted method ‚Üí Temporal activity")
            logger.info("   ‚Ä¢ No ADK call can bypass this interception")
            
            return True
        else:
            logger.error("\n‚ùå PROOF FAILED!")
            logger.error("Monkey patching is not working correctly")
            return False
        
    except Exception as e:
        logger.error(f"‚ùå Test failed with exception: {e}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """Run the definitive monkey patch proof."""
    success = await test_monkey_patch_proof()
    return success


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)