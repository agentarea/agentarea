version: "3.8"
services:
  app:
    container_name: agentarea-backend
    build:
      context: core
    ports:
      - "8000:8000"
    restart: always
    environment:
      # S3 settings
      - AWS_ACCESS_KEY_ID=${MINIO_ACCESS_KEY}
      - AWS_SECRET_ACCESS_KEY=${MINIO_SECRET_KEY}
      - AWS_REGION=${MINIO_REGION}
      - S3_BUCKET_NAME=${DOCUMENTS_BUCKET}
      - AWS_ENDPOINT_URL=http://minio:9000
      # Database settings
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      # MCP settings
      - MCP_MANAGER_URL=http://mcp-manager:8000
      - REDIS_URL=redis://redis:6379
      - MCP_CLIENT_TIMEOUT=30
      # Server settings
      - PORT=${PORT:-8000}
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - WORKFLOW__TEMPORAL_SERVER_URL=temporal:7233
      - RELOAD=${RELOAD:-true}
      - WORKERS=${WORKERS:-1}
      # Ollama settings
      - OLLAMA_BASE_URL=http://ollama:11434
    volumes:
      - ./core/agentarea:/app/agentarea
      - ./core/alembic:/app/alembic
      - ${INFISICAL_TOKEN_VOLUME}:/app/bootstrap
    depends_on:
      db:
        condition: service_healthy
      minio:
        condition: service_healthy
      redis:
        condition: service_started
      app_migrations:
        condition: service_completed_successfully
      bootstrap:
        condition: service_completed_successfully
      mcp-manager:
        condition: service_healthy
    networks:
      - default
      - mcp-network
      - temporal-network
    command: ["python", "-m", "cli", "serve", "--reload", "--log-level=${LOG_LEVEL:-info}", "--workers=${WORKERS:-1}"]

  app_migrations:
    build:
      context: core
    environment:
    ## Have to add it for now
          # S3 settings
      - AWS_ACCESS_KEY_ID=${MINIO_ACCESS_KEY}
      - AWS_SECRET_ACCESS_KEY=${MINIO_SECRET_KEY}
      - AWS_REGION=${MINIO_REGION}
      - S3_BUCKET_NAME=${DOCUMENTS_BUCKET}
      - AWS_ENDPOINT_URL=http://minio:9000
      # Only database settings
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    volumes:
      - ./core/alembic:/app/alembic
    depends_on:
      db:
        condition: service_healthy
    command: ["python", "-m", "cli", "migrate"]

  bootstrap:
    build:
      context: bootstrap
      dockerfile: Dockerfile
    volumes:
      - ./data:/app/llm
      - ${INFISICAL_TOKEN_VOLUME:-./.data}/bootstrap/data}:/app/data
    environment:
      - MINIO_ROOT_USER=${MINIO_ACCESS_KEY}
      - MINIO_ROOT_PASSWORD=${MINIO_SECRET_KEY}
      - MINIO_ENDPOINT=http://minio:9000
      - ADMIN_EMAIL=${ADMIN_EMAIL:-admin@example.com}
      - ADMIN_PASSWORD=${ADMIN_PASSWORD:-your-secure-password}
      - ORGANIZATION_NAME=${ORGANIZATION_NAME:-your-org-name}
      - INFISICAL_URL=http://infisical:8080
      - DATABASE_URL=postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
      - LLM_PROVIDERS_YAML=/app/llm/providers.yaml
      - MCP_PROVIDERS_YAML=/app/llm/mcp_providers.yaml
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_HOST=db
      - POSTGRES_PORT=5432
    depends_on:
      db:
        condition: service_healthy
      minio:
        condition: service_healthy
      app_migrations:
        condition: service_completed_successfully
      infisical:
        condition: service_started

  minio:
    image: minio/minio
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    environment:
      - MINIO_ROOT_USER=${MINIO_ACCESS_KEY}
      - MINIO_ROOT_PASSWORD=${MINIO_SECRET_KEY}
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 5s
      timeout: 5s
      retries: 5

  db:
    image: postgres:15
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - default
      - temporal-network

  infisical:
    container_name: infisical-backend
    restart: always
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
    image: infisical/infisical:latest-postgres
    env_file: .env
    ports:
      - 3333:8080
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/infisical

  redis:
    image: redis
    container_name: infisical-dev-redis
    env_file: .env
    restart: always
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    ports:
      - 6379:6379
    volumes:
      - redis_data:/data
    networks:
      - default
      - temporal-network

  # MCP Infrastructure Services
  mcp-manager:
    build:
      context: mcp-infrastructure/go-mcp-manager
      dockerfile: Dockerfile
    container_name: mcp-manager
    restart: unless-stopped
    privileged: true
    expose:
      - "8000"
    tmpfs:
      - /tmp
      - /run
    volumes:
      - mcp_containers:/var/lib/containers/storage
      - ./mcp-infrastructure/docker/templates:/app/templates:ro
      - /sys/fs/cgroup:/sys/fs/cgroup:rw
    networks:
      - mcp-network
    environment:
      - LOG_LEVEL=INFO
      - LOG_FORMAT=json
      - CADDY_API_URL=http://caddy:2019
      - CADDY_HOST=caddy
      - CONTAINERS_STORAGE_DRIVER=overlay
      - CONTAINERS_STORAGE_RUNROOT=/tmp/containers
      - CONTAINERS_STORAGE_GRAPHROOT=/var/lib/containers/storage
      - TEMPLATES_DIR=/app/templates
      - REDIS_URL=redis://redis:6379
    depends_on:
      caddy:
        condition: service_healthy
      redis:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  caddy:
    image: caddy:2.8-alpine
    container_name: mcp-caddy
    restart: unless-stopped
    ports:
      - "81:80"  # Different port to avoid conflict with main app
      - "444:443" # Different port to avoid conflict
      - "2019:2019"  # Caddy API
    volumes:
      - mcp_caddy_data:/data
      - mcp_caddy_config:/config
      - ./mcp-infrastructure/caddy/Caddyfile:/etc/caddy/Caddyfile:ro
    networks:
      - mcp-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:2019/config/"] 
      interval: 30s
      timeout: 10s
      retries: 3
    command: ["caddy", "run", "--config", "/etc/caddy/Caddyfile", "--adapter", "caddyfile"]

  # Temporal Infrastructure Services
  temporal:
    container_name: temporal
    restart: unless-stopped
    depends_on:
      db:
        condition: service_healthy
      bootstrap:
        condition: service_completed_successfully
    environment:
      - DB=postgres12
      - DB_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PWD=${POSTGRES_PASSWORD}
      - POSTGRES_SEEDS=db
      - DBNAME=temporal
      - DYNAMIC_CONFIG_FILE_PATH=config/dynamicconfig/development-sql.yaml
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CLI_ADDRESS=temporal:7233
    image: temporalio/auto-setup:1.27
    networks:
      - temporal-network
    ports:
      - 7233:7233
    labels:
      kompose.volume.type: configMap
    volumes:
      - ./core/temporal-config:/etc/temporal/config/dynamicconfig
    # healthcheck:
    #   test: ["CMD", "curl", "-f", "http://localhost:7233/"]
    #   interval: 30s
    #   timeout: 10s
    #   retries: 5
    #   start_period: 60s
  temporal-admin-tools:
    image: temporalio/admin-tools:1.27
    container_name: temporal-admin-tools
    depends_on:
      - temporal
    environment:
      - TEMPORAL_CLI_ADDRESS=temporal:7233
    networks:
      - temporal-network
    stdin_open: true
    tty: true

  temporal-ui:
    container_name: temporal-ui
    # depends_on:
    #   temporal:
    #     condition: service_healthy
    environment:
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CORS_ORIGINS=http://localhost:3000
    image: temporalio/ui:2.21.3
    networks:
      - temporal-network
    ports:
      - 8081:8080

  # Ollama Service
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_ORIGINS=*
      - OLLAMA_HOST=0.0.0.0
    networks:
      - default
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # AgentArea Worker Service
  # agentarea-worker:
  #   build:
  #     context: core
  #     dockerfile: Dockerfile
  #   container_name: agentarea-worker
  #   depends_on:
  #     db:
  #       condition: service_healthy
  #     redis:
  #       condition: service_started
  #   environment:
  #     # Database
  #     - POSTGRES_HOST=db
  #     - POSTGRES_PORT=5432
  #     - POSTGRES_USER=${POSTGRES_USER}
  #     - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
  #     - POSTGRES_DB=${POSTGRES_DB}
      
  #     # Redis
  #     - REDIS_URL=redis://redis:6379/1
      
  #     # Workflow settings
  #     - WORKFLOW__USE_WORKFLOW_EXECUTION=true
  #     - WORKFLOW__WORKFLOW_ENGINE=temporal
  #     - WORKFLOW__TEMPORAL_SERVER_URL=temporal:7233
  #     - WORKFLOW__TEMPORAL_NAMESPACE=default
  #     - WORKFLOW__TEMPORAL_TASK_QUEUE=agent-tasks
  #     - WORKFLOW__TEMPORAL_MAX_CONCURRENT_ACTIVITIES=10
  #     - WORKFLOW__TEMPORAL_MAX_CONCURRENT_WORKFLOWS=5
      
  #     # Task execution
  #     - TASK__ENABLE_DYNAMIC_ACTIVITY_DISCOVERY=true
      
  #     # Development
  #     - DEBUG=true
  #     - ENVIRONMENT=development
  #   networks:
  #     - temporal-network
  #     - default
  #   volumes:
  #     - ./core:/app
  #   working_dir: /app
  #   command: >
  #     sh -c "
  #       echo 'Waiting for Temporal to be ready...' &&
  #       sleep 15 &&
  #       echo 'Starting Temporal worker...' &&
  #       python agentarea/workflows/temporal_worker.py
  #     "



volumes:
  postgres_data:
  minio_data: 
  redis_data:
  infisical_bootstrap:
  mcp_containers:
    driver: local
  mcp_caddy_data:
    driver: local
  mcp_caddy_config:
    driver: local

networks:
  infisical:
    driver: bridge
  mcp-network:
    driver: bridge
  temporal-network:
    driver: bridge

